#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HueæŸ¥è¯¢è‡ªåŠ¨åŒ–è„šæœ¬
åŠŸèƒ½ï¼šè‡ªåŠ¨è¿æ¥Hueï¼Œæ‰§è¡Œè´¢åŠ¡æ¯›åˆ©æŸ¥è¯¢ï¼Œä¼˜åŒ–æ€§èƒ½ï¼Œå¯¼å‡ºæ•°æ®
ä½œè€…ï¼šAIåŠ©æ‰‹
é€‚ç”¨ï¼šå›æ”¶å®è´¢åŠ¡æ•°æ®åˆ†æ
"""

import requests
import json
import time
import pandas as pd
from datetime import datetime, timedelta
import logging
import os
from typing import Dict, List, Optional
import configparser

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hue_automation.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class HueAutomation:
    """HueæŸ¥è¯¢è‡ªåŠ¨åŒ–ç±»"""
    
    def __init__(self, config_file: str = 'hue_config.ini'):
        """
        åˆå§‹åŒ–Hueè‡ªåŠ¨åŒ–å·¥å…·
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_file)
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        
        # Hueè¿æ¥ä¿¡æ¯
        self.hue_url = self.config.get('hue', 'base_url')
        self.username = self.config.get('hue', 'username')
        self.password = self.config.get('hue', 'password')
        
        # æŸ¥è¯¢é…ç½®
        self.query_timeout = self.config.getint('query', 'timeout', fallback=300)
        self.max_retries = self.config.getint('query', 'max_retries', fallback=3)
        
        # æ•°æ®å¯¼å‡ºé…ç½®
        self.export_dir = self.config.get('export', 'directory', fallback='./exports')
        self.ensure_export_dir()
        
        logger.info("Hueè‡ªåŠ¨åŒ–å·¥å…·åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self, config_file: str) -> configparser.ConfigParser:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config = configparser.ConfigParser()
        
        if not os.path.exists(config_file):
            # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
            self._create_default_config(config_file)
        
        config.read(config_file, encoding='utf-8')
        return config
    
    def _create_default_config(self, config_file: str):
        """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
        config = configparser.ConfigParser()
        
        config['hue'] = {
            'base_url': 'http://119.23.30.106:8889',
            'username': 'your_username',
            'password': 'your_password'
        }
        
        config['query'] = {
            'timeout': '300',
            'max_retries': '3',
            'batch_size': '10000'
        }
        
        config['export'] = {
            'directory': './exports',
            'format': 'csv',
            'encoding': 'utf-8'
        }
        
        config['optimization'] = {
            'enable_partition_pruning': 'true',
            'enable_column_pruning': 'true',
            'max_memory': '2GB'
        }
        
        with open(config_file, 'w', encoding='utf-8') as f:
            config.write(f)
        
        logger.info(f"å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {config_file}")
        logger.info("è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œå¡«å…¥æ­£ç¡®çš„Hueè¿æ¥ä¿¡æ¯")
    
    def ensure_export_dir(self):
        """ç¡®ä¿å¯¼å‡ºç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.export_dir):
            os.makedirs(self.export_dir)
            logger.info(f"åˆ›å»ºå¯¼å‡ºç›®å½•: {self.export_dir}")
    
    def login(self) -> bool:
        """
        ç™»å½•Hue
        
        Returns:
            bool: ç™»å½•æ˜¯å¦æˆåŠŸ
        """
        try:
            login_url = f"{self.hue_url}/accounts/login/"
            
            # è·å–ç™»å½•é¡µé¢ï¼Œè·å–CSRF token
            response = self.session.get(login_url)
            if response.status_code != 200:
                logger.error(f"æ— æ³•è®¿é—®ç™»å½•é¡µé¢: {response.status_code}")
                return False
            
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„Hueç™»å½•æœºåˆ¶è°ƒæ•´
            # æœ‰äº›Hueç‰ˆæœ¬ä½¿ç”¨ä¸åŒçš„è®¤è¯æ–¹å¼
            login_data = {
                'username': self.username,
                'password': self.password,
                'csrfmiddlewaretoken': self._extract_csrf_token(response.text)
            }
            
            response = self.session.post(login_url, data=login_data)
            
            if response.status_code == 200 and 'dashboard' in response.url:
                logger.info("Hueç™»å½•æˆåŠŸ")
                return True
            else:
                logger.error("Hueç™»å½•å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"ç™»å½•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _extract_csrf_token(self, html_content: str) -> str:
        """ä»HTMLä¸­æå–CSRF token"""
        try:
            # ç®€å•çš„CSRF tokenæå–é€»è¾‘
            import re
            match = re.search(r'name="csrfmiddlewaretoken" value="([^"]+)"', html_content)
            return match.group(1) if match else ""
        except:
            return ""
    
    def execute_query(self, sql_query: str, query_name: str = "è´¢åŠ¡æ¯›åˆ©æŸ¥è¯¢") -> Optional[pd.DataFrame]:
        """
        æ‰§è¡ŒSQLæŸ¥è¯¢
        
        Args:
            sql_query: SQLæŸ¥è¯¢è¯­å¥
            query_name: æŸ¥è¯¢åç§°ï¼Œç”¨äºæ—¥å¿—è®°å½•
            
        Returns:
            pd.DataFrame: æŸ¥è¯¢ç»“æœï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            logger.info(f"å¼€å§‹æ‰§è¡ŒæŸ¥è¯¢: {query_name}")
            
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„Hue APIè°ƒæ•´
            # Hueé€šå¸¸é€šè¿‡REST APIæ‰§è¡ŒæŸ¥è¯¢
            query_url = f"{self.hue_url}/api/query/execute"
            
            query_data = {
                'query': sql_query,
                'type': 'hive',  # æ ¹æ®å®é™…æ•°æ®åº“ç±»å‹è°ƒæ•´
                'name': query_name
            }
            
            response = self.session.post(query_url, json=query_data, timeout=self.query_timeout)
            
            if response.status_code == 200:
                result = response.json()
                query_id = result.get('id')
                
                if query_id:
                    logger.info(f"æŸ¥è¯¢å·²æäº¤ï¼ŒID: {query_id}")
                    return self._wait_for_completion(query_id)
                else:
                    logger.error("æŸ¥è¯¢æäº¤å¤±è´¥ï¼Œæœªè·å–åˆ°æŸ¥è¯¢ID")
                    return None
            else:
                logger.error(f"æŸ¥è¯¢æäº¤å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"æ‰§è¡ŒæŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def _wait_for_completion(self, query_id: str) -> Optional[pd.DataFrame]:
        """ç­‰å¾…æŸ¥è¯¢å®Œæˆå¹¶è·å–ç»“æœ"""
        try:
            status_url = f"{self.hue_url}/api/query/{query_id}/status"
            result_url = f"{self.hue_url}/api/query/{query_id}/result"
            
            # ç­‰å¾…æŸ¥è¯¢å®Œæˆ
            for attempt in range(self.max_retries):
                time.sleep(5)  # ç­‰å¾…5ç§’
                
                status_response = self.session.get(status_url)
                if status_response.status_code == 200:
                    status = status_response.json().get('status')
                    
                    if status == 'finished':
                        logger.info("æŸ¥è¯¢æ‰§è¡Œå®Œæˆ")
                        return self._fetch_results(result_url)
                    elif status == 'failed':
                        logger.error("æŸ¥è¯¢æ‰§è¡Œå¤±è´¥")
                        return None
                    elif status == 'running':
                        logger.info(f"æŸ¥è¯¢æ­£åœ¨æ‰§è¡Œä¸­... (å°è¯• {attempt + 1}/{self.max_retries})")
                        continue
                
                if attempt == self.max_retries - 1:
                    logger.error("æŸ¥è¯¢è¶…æ—¶")
                    return None
            
            return None
            
        except Exception as e:
            logger.error(f"ç­‰å¾…æŸ¥è¯¢å®Œæˆæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def _fetch_results(self, result_url: str) -> Optional[pd.DataFrame]:
        """è·å–æŸ¥è¯¢ç»“æœ"""
        try:
            response = self.session.get(result_url)
            if response.status_code == 200:
                result_data = response.json()
                
                # è§£æç»“æœæ•°æ®
                if 'data' in result_data:
                    df = pd.DataFrame(result_data['data'])
                    logger.info(f"æˆåŠŸè·å–æŸ¥è¯¢ç»“æœï¼Œå…± {len(df)} è¡Œæ•°æ®")
                    return df
                else:
                    logger.error("æŸ¥è¯¢ç»“æœæ ¼å¼ä¸æ­£ç¡®")
                    return None
            else:
                logger.error(f"è·å–æŸ¥è¯¢ç»“æœå¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"è·å–æŸ¥è¯¢ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def optimize_query(self, sql_query: str) -> str:
        """
        ä¼˜åŒ–SQLæŸ¥è¯¢
        
        Args:
            sql_query: åŸå§‹SQLæŸ¥è¯¢
            
        Returns:
            str: ä¼˜åŒ–åçš„SQLæŸ¥è¯¢
        """
        logger.info("å¼€å§‹ä¼˜åŒ–SQLæŸ¥è¯¢")
        
        # åŸºç¡€ä¼˜åŒ–è§„åˆ™
        optimized_query = sql_query
        
        # 1. æ·»åŠ åˆ†åŒºè£å‰ªæç¤º
        if 'WHERE' in sql_query.upper():
            optimized_query = optimized_query.replace(
                'WHERE', 
                'WHERE /*+ PARTITION_PRUNE */'
            )
        
        # 2. æ·»åŠ åˆ—è£å‰ªæç¤º
        if 'SELECT' in sql_query.upper():
            optimized_query = optimized_query.replace(
                'SELECT', 
                'SELECT /*+ COLUMN_PRUNE */'
            )
        
        # 3. ä¼˜åŒ–UNION ALLï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'UNION ALL' in sql_query.upper():
            # ç¡®ä¿UNION ALLçš„åˆ—é¡ºåºä¸€è‡´
            optimized_query = self._optimize_union_all(optimized_query)
        
        # 4. æ·»åŠ LIMITé™åˆ¶ï¼ˆå¦‚æœæŸ¥è¯¢ç»“æœå¾ˆå¤§ï¼‰
        if 'LIMIT' not in sql_query.upper():
            optimized_query += '\nLIMIT 1000000'  # é™åˆ¶ç»“æœå¤§å°
        
        logger.info("SQLæŸ¥è¯¢ä¼˜åŒ–å®Œæˆ")
        return optimized_query
    
    def _optimize_union_all(self, sql_query: str) -> str:
        """ä¼˜åŒ–UNION ALLæŸ¥è¯¢"""
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„UNION ALLä¼˜åŒ–é€»è¾‘
            # æ¯”å¦‚æ£€æŸ¥åˆ—ç±»å‹ä¸€è‡´æ€§ã€æ·»åŠ é€‚å½“çš„ç´¢å¼•æç¤ºç­‰
            return sql_query
        except:
            return sql_query
    
    def export_data(self, df: pd.DataFrame, filename: str, format: str = 'csv') -> str:
        """
        å¯¼å‡ºæ•°æ®åˆ°æ–‡ä»¶
        
        Args:
            df: è¦å¯¼å‡ºçš„æ•°æ®æ¡†
            filename: æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            format: å¯¼å‡ºæ ¼å¼ (csv, excel, json)
            
        Returns:
            str: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename_with_timestamp = f"{filename}_{timestamp}"
            
            if format.lower() == 'csv':
                filepath = os.path.join(self.export_dir, f"{filename_with_timestamp}.csv")
                df.to_csv(filepath, index=False, encoding='utf-8-sig')
            elif format.lower() == 'excel':
                filepath = os.path.join(self.export_dir, f"{filename_with_timestamp}.xlsx")
                df.to_excel(filepath, index=False, engine='openpyxl')
            elif format.lower() == 'json':
                filepath = os.path.join(self.export_dir, f"{filename_with_timestamp}.json")
                df.to_json(filepath, orient='records', force_ascii=False, indent=2)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format}")
            
            logger.info(f"æ•°æ®å¯¼å‡ºæˆåŠŸ: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
            return ""
    
    def analyze_data(self, df: pd.DataFrame) -> Dict:
        """
        åˆ†ææ•°æ®ï¼Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        
        Args:
            df: è¦åˆ†æçš„æ•°æ®æ¡†
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        try:
            logger.info("å¼€å§‹æ•°æ®åˆ†æ")
            
            analysis_result = {
                'æ•°æ®æ¦‚è§ˆ': {
                    'æ€»è¡Œæ•°': len(df),
                    'æ€»åˆ—æ•°': len(df.columns),
                    'æ•°æ®å¤§å°': f"{df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB"
                },
                'åˆ—ä¿¡æ¯': {},
                'æ•°å€¼åˆ—ç»Ÿè®¡': {},
                'ç¼ºå¤±å€¼ç»Ÿè®¡': {}
            }
            
            # åˆ†ææ¯åˆ—çš„ä¿¡æ¯
            for col in df.columns:
                col_info = {
                    'æ•°æ®ç±»å‹': str(df[col].dtype),
                    'å”¯ä¸€å€¼æ•°é‡': df[col].nunique(),
                    'ç¼ºå¤±å€¼æ•°é‡': df[col].isnull().sum(),
                    'ç¼ºå¤±å€¼æ¯”ä¾‹': f"{df[col].isnull().sum() / len(df) * 100:.2f}%"
                }
                
                analysis_result['åˆ—ä¿¡æ¯'][col] = col_info
                
                # æ•°å€¼åˆ—çš„ç‰¹æ®Šç»Ÿè®¡
                if pd.api.types.is_numeric_dtype(df[col]):
                    analysis_result['æ•°å€¼åˆ—ç»Ÿè®¡'][col] = {
                        'æœ€å°å€¼': df[col].min(),
                        'æœ€å¤§å€¼': df[col].max(),
                        'å¹³å‡å€¼': df[col].mean(),
                        'ä¸­ä½æ•°': df[col].median(),
                        'æ ‡å‡†å·®': df[col].std()
                    }
            
            # ç”Ÿæˆåˆ†ææŠ¥å‘Šæ–‡ä»¶
            report_filename = f"æ•°æ®åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            report_path = os.path.join(self.export_dir, report_filename)
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("=== è´¢åŠ¡æ¯›åˆ©æ•°æ®åˆ†ææŠ¥å‘Š ===\n\n")
                
                # å†™å…¥æ•°æ®æ¦‚è§ˆ
                f.write("1. æ•°æ®æ¦‚è§ˆ\n")
                f.write("-" * 30 + "\n")
                for key, value in analysis_result['æ•°æ®æ¦‚è§ˆ'].items():
                    f.write(f"{key}: {value}\n")
                f.write("\n")
                
                # å†™å…¥åˆ—ä¿¡æ¯
                f.write("2. åˆ—ä¿¡æ¯\n")
                f.write("-" * 30 + "\n")
                for col, info in analysis_result['åˆ—ä¿¡æ¯'].items():
                    f.write(f"\nåˆ—å: {col}\n")
                    for key, value in info.items():
                        f.write(f"  {key}: {value}\n")
                
                # å†™å…¥æ•°å€¼åˆ—ç»Ÿè®¡
                if analysis_result['æ•°å€¼åˆ—ç»Ÿè®¡']:
                    f.write("\n3. æ•°å€¼åˆ—ç»Ÿè®¡\n")
                    f.write("-" * 30 + "\n")
                    for col, stats in analysis_result['æ•°å€¼åˆ—ç»Ÿè®¡'].items():
                        f.write(f"\nåˆ—å: {col}\n")
                        for key, value in stats.items():
                            if pd.notna(value):
                                f.write(f"  {key}: {value:.2f}\n")
            
            logger.info(f"æ•°æ®åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"æ•°æ®åˆ†æå¤±è´¥: {e}")
            return {}
    
    def run_financial_analysis(self):
        """è¿è¡Œå®Œæ•´çš„è´¢åŠ¡åˆ†ææµç¨‹"""
        try:
            logger.info("å¼€å§‹è¿è¡Œè´¢åŠ¡åˆ†ææµç¨‹")
            
            # 1. ç™»å½•Hue
            if not self.login():
                logger.error("Hueç™»å½•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                return
            
            # 2. è¯»å–è´¢åŠ¡æ¯›åˆ©SQL
            sql_file = '/Users/boxie/SQL/è´¢åŠ¡/è´¢åŠ¡æ¯›åˆ©.sql'
            if not os.path.exists(sql_file):
                logger.error(f"SQLæ–‡ä»¶ä¸å­˜åœ¨: {sql_file}")
                return
            
            with open(sql_file, 'r', encoding='utf-8') as f:
                original_sql = f.read()
            
            # 3. ä¼˜åŒ–SQLæŸ¥è¯¢
            optimized_sql = self.optimize_query(original_sql)
            
            # 4. æ‰§è¡ŒæŸ¥è¯¢
            df = self.execute_query(optimized_sql, "è´¢åŠ¡æ¯›åˆ©æŸ¥è¯¢")
            if df is None:
                logger.error("æŸ¥è¯¢æ‰§è¡Œå¤±è´¥")
                return
            
            # 5. å¯¼å‡ºæ•°æ®
            csv_path = self.export_data(df, "è´¢åŠ¡æ¯›åˆ©æ•°æ®", "csv")
            excel_path = self.export_data(df, "è´¢åŠ¡æ¯›åˆ©æ•°æ®", "excel")
            
            # 6. æ•°æ®åˆ†æ
            analysis_result = self.analyze_data(df)
            
            # 7. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
            self._generate_summary_report(df, csv_path, excel_path, analysis_result)
            
            logger.info("è´¢åŠ¡åˆ†ææµç¨‹å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"è¿è¡Œè´¢åŠ¡åˆ†ææµç¨‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def _generate_summary_report(self, df: pd.DataFrame, csv_path: str, excel_path: str, analysis_result: Dict):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        try:
            summary_filename = f"è´¢åŠ¡åˆ†ææ€»ç»“æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            summary_path = os.path.join(self.export_dir, summary_filename)
            
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write("# è´¢åŠ¡æ¯›åˆ©æ•°æ®åˆ†ææ€»ç»“æŠ¥å‘Š\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("## ğŸ“Š æ•°æ®æ¦‚è§ˆ\n\n")
                f.write(f"- **æ€»è®°å½•æ•°**: {len(df):,} æ¡\n")
                f.write(f"- **æ€»å­—æ®µæ•°**: {len(df.columns)} ä¸ª\n")
                f.write(f"- **æ•°æ®å¤§å°**: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\n\n")
                
                f.write("## ğŸ“ å¯¼å‡ºæ–‡ä»¶\n\n")
                f.write(f"- **CSVæ–‡ä»¶**: {csv_path}\n")
                f.write(f"- **Excelæ–‡ä»¶**: {excel_path}\n\n")
                
                f.write("## ğŸ” å…³é”®æŒ‡æ ‡åˆ†æ\n\n")
                
                # åˆ†æå…³é”®è´¢åŠ¡æŒ‡æ ‡
                if 'foffer_amounta' in df.columns:
                    total_offer_a = df['foffer_amounta'].sum()
                    f.write(f"- **æŠ¥ä»·é‡‘é¢Aæ€»è®¡**: Â¥{total_offer_a:,.2f}\n")
                
                if 'fcost_amounta' in df.columns:
                    total_cost_a = df['fcost_amounta'].sum()
                    f.write(f"- **æˆæœ¬é‡‘é¢Aæ€»è®¡**: Â¥{total_cost_a:,.2f}\n")
                
                if 'fdetection_amount' in df.columns:
                    total_detection = df['fdetection_amount'].sum()
                    f.write(f"- **æ£€æµ‹é‡‘é¢æ€»è®¡**: Â¥{total_detection:,.2f}\n")
                
                f.write("\n## ğŸ“ˆ æ•°æ®è´¨é‡\n\n")
                
                # æ•°æ®è´¨é‡åˆ†æ
                missing_data = df.isnull().sum().sum()
                total_cells = df.size
                data_quality = (1 - missing_data / total_cells) * 100
                
                f.write(f"- **æ•°æ®å®Œæ•´åº¦**: {data_quality:.2f}%\n")
                f.write(f"- **ç¼ºå¤±å€¼æ•°é‡**: {missing_data:,} ä¸ª\n")
                f.write(f"- **æ€»æ•°æ®å•å…ƒæ ¼**: {total_cells:,} ä¸ª\n\n")
                
                f.write("## ğŸ¯ å»ºè®®å’Œæ³¨æ„äº‹é¡¹\n\n")
                f.write("1. **æ•°æ®éªŒè¯**: å»ºè®®å¯¹å…³é”®è´¢åŠ¡æ•°æ®è¿›è¡Œäº¤å‰éªŒè¯\n")
                f.write("2. **æ€§èƒ½ä¼˜åŒ–**: æŸ¥è¯¢å·²è¿›è¡ŒåŸºç¡€ä¼˜åŒ–ï¼Œå¯æ ¹æ®å®é™…æ€§èƒ½è¿›ä¸€æ­¥è°ƒæ•´\n")
                f.write("3. **å®šæœŸæ›´æ–°**: å»ºè®®å®šæœŸè¿è¡Œæ­¤åˆ†æï¼Œç›‘æ§è´¢åŠ¡æ•°æ®å˜åŒ–\n")
                f.write("4. **å¼‚å¸¸æ£€æµ‹**: å…³æ³¨æ•°æ®ä¸­çš„å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼\n\n")
                
                f.write("---\n")
                f.write("*æœ¬æŠ¥å‘Šç”±Hueè‡ªåŠ¨åŒ–è„šæœ¬è‡ªåŠ¨ç”Ÿæˆ*")
            
            logger.info(f"æ€»ç»“æŠ¥å‘Šå·²ç”Ÿæˆ: {summary_path}")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ HueæŸ¥è¯¢è‡ªåŠ¨åŒ–å·¥å…·å¯åŠ¨ä¸­...")
    print("=" * 50)
    
    try:
        # åˆ›å»ºè‡ªåŠ¨åŒ–å·¥å…·å®ä¾‹
        automation = HueAutomation()
        
        # è¿è¡Œè´¢åŠ¡åˆ†æ
        automation.run_financial_analysis()
        
        print("\nâœ… è‡ªåŠ¨åŒ–æµç¨‹å®Œæˆï¼")
        print(f"ğŸ“ è¯·æŸ¥çœ‹ {automation.export_dir} ç›®å½•ä¸‹çš„ç»“æœæ–‡ä»¶")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        logger.error(f"ä¸»ç¨‹åºè¿è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    main()
